{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xljeWnhOnvjA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, logging, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5nFSururwaT"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"bert-base-multilingual-uncased\"\n",
        "RANDOM_STATE = 9\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 5e-5\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTsoVCOJr8S9"
      },
      "outputs": [],
      "source": [
        "#load the data\n",
        "train_data = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/sample_data/test.csv\")\n",
        "valid_data = pd.read_csv(\"/content/sample_data/valid.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSOkZPRIuwKp"
      },
      "outputs": [],
      "source": [
        "# Concatenate the datasets into a single dataframe\n",
        "lang_data = pd.concat([train_data, test_data, valid_data], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWC9I9glu_aK"
      },
      "outputs": [],
      "source": [
        "print(\"Combined Dataset Summary:\")\n",
        "print(lang_data.sample(n=30, random_state=12345))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh7tdW4ruBSJ"
      },
      "outputs": [],
      "source": [
        "# Plotting the structure of the target variable\n",
        "lang_counts = lang_data[\"labels\"].value_counts(normalize=True)\n",
        "lang_counts.plot(kind=\"bar\")\n",
        "plt.title(\"Shares of objects in each language class\", fontsize=15)\n",
        "plt.ylabel(\"Proportion of objects\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJeN8Tjdwhj5"
      },
      "outputs": [],
      "source": [
        "# Retrieving the text data\n",
        "texts_data = lang_data[\"text\"].values.astype(\"U\")\n",
        "# Retrieving the labels data\n",
        "labels_data = lang_data[\"labels\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI8EvvtgvKwM"
      },
      "outputs": [],
      "source": [
        "# Instantiating the LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encoding the labels\n",
        "labels_data_encoded = label_encoder.fit_transform(labels_data)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Displaying the encoding results\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    print(f\"{idx:<2} => {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5cGnn4KxGZj"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training (80%) and the combination of validation and testing (20%)\n",
        "train_texts, val_test_texts, train_labels, val_test_labels = train_test_split(\n",
        "    texts_data, labels_data_encoded, train_size=0.8, random_state=RANDOM_STATE,stratify=labels_data_encoded,\n",
        ")\n",
        "\n",
        "# Further splitting the validation and testing sets\n",
        "validation_texts, testing_texts, validation_labels, testing_labels = train_test_split(\n",
        "    val_test_texts, val_test_labels, test_size=0.5, random_state=RANDOM_STATE, stratify=val_test_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNYiuNO3ykQi"
      },
      "outputs": [],
      "source": [
        "# Verifying the correctness of dimensions\n",
        "assert (\n",
        "    train_texts.shape[0] + validation_texts.shape[0] + testing_texts.shape[0] == texts_data.shape[0]\n",
        ")\n",
        "\n",
        "# Displaying the number of objects in each set\n",
        "train_texts.shape[0], validation_texts.shape[0], testing_texts.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcSQTlyH4QUf"
      },
      "outputs": [],
      "source": [
        "# Instantiating a BERT tokenizer\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCDa31AI4VWY"
      },
      "outputs": [],
      "source": [
        "# Tokenizing the training examples\n",
        "training_encodings = bert_tokenizer(\n",
        "    list(train_texts),\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        ")\n",
        "\n",
        "# Tokenizing the validation examples\n",
        "validation_encodings = bert_tokenizer(\n",
        "    list(validation_texts),\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        ")\n",
        "\n",
        "# Tokenizing the testing examples\n",
        "testing_encodings = bert_tokenizer(\n",
        "    list(testing_texts),\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0Rkk38b40Pd"
      },
      "outputs": [],
      "source": [
        "def display_encodings_info(\n",
        "    tokenizer,\n",
        "    encodings,\n",
        "    texts,\n",
        "    labels,\n",
        "    text_idx\n",
        "):\n",
        "    \"\"\"Shows the original, encoded and decoded texts.\"\"\"\n",
        "    # Displaying the original text\n",
        "    text = texts[text_idx]\n",
        "    print(f\"Input text:\\n{text}\\n\")\n",
        "\n",
        "    # Displaying the language of the text\n",
        "    lang_label = labels[text_idx]\n",
        "    lang = class_names[lang_label]\n",
        "    print(f\"Language: {lang}\\n\")\n",
        "\n",
        "    # Displaying the encoded text\n",
        "    text_encoded = encodings[\"input_ids\"][text_idx]\n",
        "    print(f\"Tokenized input text (encoded):\\n{text_encoded}\\n\")\n",
        "\n",
        "    # Displaying the decoded text\n",
        "    text_decoded = tokenizer.convert_ids_to_tokens(text_encoded)\n",
        "    print(f\"Tokenized input text (decoded):\\n{text_decoded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7r0n_Fn44c7"
      },
      "outputs": [],
      "source": [
        "display_encodings_info(\n",
        "    tokenizer=bert_tokenizer,\n",
        "    encodings=training_encodings,\n",
        "    texts=train_texts,\n",
        "    labels=train_labels,\n",
        "    text_idx=990,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_FDn0Gt5Bc_"
      },
      "outputs": [],
      "source": [
        "display_encodings_info(\n",
        "    tokenizer=bert_tokenizer,\n",
        "    encodings=validation_encodings,\n",
        "    texts=validation_texts,\n",
        "    labels=validation_labels,\n",
        "    text_idx=1033,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWM0UtD85F4D"
      },
      "outputs": [],
      "source": [
        "display_encodings_info(\n",
        "    tokenizer=bert_tokenizer,\n",
        "    encodings=testing_encodings,\n",
        "    texts=testing_texts,\n",
        "    labels=testing_labels,\n",
        "    text_idx=1010,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxjahoeT5NeP"
      },
      "outputs": [],
      "source": [
        "#Creating Dataset and Dataloader\n",
        "class LanguageDataset(Dataset):\n",
        "    \"\"\"Class for creating a custom dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, encodings, labels):\n",
        "        \"\"\"Constructor for LanguageDataset class.\"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Computes the number of the dataset objects.\"\"\"\n",
        "        dataset_length = len(self.labels)\n",
        "\n",
        "        return dataset_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns the corresponding samples for index given.\"\"\"\n",
        "        item = {key: torch.tensor(value[idx])\n",
        "                for key, value in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmewDYiB5XNc"
      },
      "outputs": [],
      "source": [
        "# Initializing the training dataset\n",
        "training_dataset = LanguageDataset(\n",
        "    encodings=training_encodings,\n",
        "    labels=train_labels,\n",
        ")\n",
        "\n",
        "# Initializing the validation dataset\n",
        "validation_dataset = LanguageDataset(\n",
        "    encodings=validation_encodings,\n",
        "    labels=validation_labels,\n",
        ")\n",
        "\n",
        "# Initializing the testing dataset\n",
        "testing_dataset = LanguageDataset(\n",
        "    encodings=testing_encodings,\n",
        "    labels=testing_labels,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-B0ZfyU5eJ7"
      },
      "outputs": [],
      "source": [
        "# Creating a training Dataloader\n",
        "training_dataloader = DataLoader(\n",
        "    training_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Creating a validation Dataloader\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Creating a testing Dataloader\n",
        "testing_dataloader = DataLoader(\n",
        "    testing_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUePbZ_35jdy"
      },
      "outputs": [],
      "source": [
        "print(f\"Training data examples: {len(training_dataloader.dataset):,}\")\n",
        "print(f\"Number of batches: {len(training_dataloader)}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xh5N62c5n8R"
      },
      "outputs": [],
      "source": [
        "print(f\"Validation data examples: {len(validation_dataloader.dataset)}\")\n",
        "print(f\"Number of batches: {len(validation_dataloader)}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtVQ6kVb5rdu"
      },
      "outputs": [],
      "source": [
        "print(f\"Testing data examples: {len(testing_dataloader.dataset):,}\")\n",
        "print(f\"Number of batches: {len(testing_dataloader)}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHpT7wXm5tXy"
      },
      "outputs": [],
      "source": [
        "# Creating a mapping from predictions to label names\n",
        "id2label_mappings = dict()\n",
        "for i, name in enumerate(class_names):\n",
        "    id2label_mappings[i] = name\n",
        "id2label_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzhb7fk86Bz_"
      },
      "outputs": [],
      "source": [
        " # Computing the number of classes\n",
        "num_labels = len(class_names)\n",
        "\n",
        "# Instantiating the BERT model\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label_mappings,\n",
        ")\n",
        "\n",
        "# Moving the model to DEVICE (GPU/CUDA)\n",
        "bert_model.to(DEVICE)\n",
        "\n",
        "# Defining the optimization algorithm\n",
        "optimizer = torch.optim.Adam(bert_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lS0cBpz6UcH"
      },
      "outputs": [],
      "source": [
        "bert_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ygRCrNu6cxM"
      },
      "outputs": [],
      "source": [
        "def acc_score(model, dataloader, device=DEVICE):\n",
        "    \"\"\"Computes the accuracy score for a DataLoader.\"\"\"\n",
        "    # Preallocating counter variables\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    # Turning off computing gradients\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Iteratively computing accuracy score (batch by batch)\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "\n",
        "            # Selecting the batch data (encodings, attention mask, labels)\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Using BERT to compute logits\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs[\"logits\"]\n",
        "\n",
        "            # Computing the predictions for labels\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # Computing the number of examples/correct predictions number\n",
        "            num_examples += labels.size(0)\n",
        "            correct_predictions += (predicted_labels == labels).sum()\n",
        "\n",
        "    # Computing the final accuracy score\n",
        "    accuracy_score = correct_predictions.float() / num_examples\n",
        "\n",
        "    return accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQG64Ov6uaU"
      },
      "outputs": [],
      "source": [
        "def train_bert_model(\n",
        "    model,\n",
        "    optimizer,\n",
        "    training_dataloader,\n",
        "    validation_dataloader,\n",
        "    accuracy_score_func=acc_score,\n",
        "    epochs=2,\n",
        "    batch_log_freq=100,\n",
        "    device=DEVICE\n",
        "):\n",
        "    \"\"\"Launches the fine-tuning of BERT.\"\"\"\n",
        "    # Starting the timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Going through all epochs\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Setting the model in the training mode\n",
        "        model.train()\n",
        "\n",
        "        # Going through all batches\n",
        "        for batch_idx, batch in enumerate(training_dataloader):\n",
        "\n",
        "            # Selecting the batch\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # BERT forward pass\n",
        "            outputs = model(\n",
        "                input_ids, attention_mask=attention_mask, labels=labels\n",
        "            )\n",
        "            loss, logits = outputs[\"loss\"], outputs[\"logits\"]\n",
        "\n",
        "            # BERT backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging the progress\n",
        "            if not batch_idx % batch_log_freq:\n",
        "                print (f\"Epoch {epoch+1:03d}/{epochs:03d} | \"\n",
        "                       f\"Batch {batch_idx:03d}/{len(training_dataloader):03d} | \"\n",
        "                       f\"Loss = {loss:.4f}\")\n",
        "\n",
        "        # Setting the model in the evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Disabling computing gradients\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # Computing training accuracy\n",
        "            training_accuracy_score = accuracy_score_func(\n",
        "                model=model,\n",
        "                dataloader=training_dataloader,\n",
        "            )\n",
        "            # Computing validation accuracy\n",
        "            validation_accuracy_score = accuracy_score_func(\n",
        "                model=model,\n",
        "                dataloader=validation_dataloader,\n",
        "            )\n",
        "            # Logging the accuracy scores\n",
        "            print(f\"\\nTraining accuracy = \"\n",
        "                  f\"{training_accuracy_score:.4f}\"\n",
        "                  f\"\\nValid accuracy = \"\n",
        "                  f\"{validation_accuracy_score:.4f}\\n\")\n",
        "\n",
        "        # Printing the time passed at the end of the epoch\n",
        "        time_elapsed_epoch = (time.time() - start_time) / 60\n",
        "        print(f'Time elapsed: {time_elapsed_epoch:.2f} min\\n')\n",
        "\n",
        "    # Printing the total time spent on BERT fine-tuning\n",
        "    time_elapsed_total = (time.time() - start_time) / 60\n",
        "    print(f'\\nTotal training Time: {time_elapsed_total:.2f} min')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SEOysi_6nPO"
      },
      "outputs": [],
      "source": [
        "# Training the BERT model\n",
        "bert_model = train_bert_model(\n",
        "    model=bert_model,\n",
        "    optimizer=optimizer,\n",
        "    training_dataloader=training_dataloader,\n",
        "    validation_dataloader=validation_dataloader,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    batch_log_freq=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(model, dataloader, device=DEVICE):\n",
        "    \"\"\"Predicts the labels for the DataLoader.\"\"\"\n",
        "    # Setting up counter variables\n",
        "    correct_preds, num_examples = 0, 0\n",
        "    # Preallocating the list for test predictions\n",
        "    test_predictions = []\n",
        "\n",
        "    # Disabling computing gradients\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Iterating through all batches\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "\n",
        "            # Selecting the batch\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Computing logits\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs[\"logits\"]\n",
        "\n",
        "            # Computing the predictions for labels\n",
        "            predicted_labels_batch = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # Adding the batch predictions to the list\n",
        "            test_predictions.append(predicted_labels_batch)\n",
        "\n",
        "            # Iteratively computing accuracy determinants\n",
        "            num_examples += labels.size(0)\n",
        "            correct_preds += (predicted_labels_batch == labels).sum().cpu()\n",
        "\n",
        "    # Computing final accuracy score\n",
        "    test_accuracy_score = correct_preds.float() / num_examples\n",
        "\n",
        "    # Transforming a list of tensors into one tensor\n",
        "    test_predictions_tensor = torch.cat(test_predictions).cpu()\n",
        "\n",
        "    return test_accuracy_score, test_predictions_tensor"
      ],
      "metadata": {
        "id": "o-OfnlXBNVIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing test accuracy and test predictions\n",
        "accuracy_test, predictions_test = evaluate_test(\n",
        "    model=bert_model, dataloader=testing_dataloader\n",
        ")\n",
        "\n",
        "print(f\"Test accuracy: {accuracy_test:.4f}\")"
      ],
      "metadata": {
        "id": "6pR4VyCoNo1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}