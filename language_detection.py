# -*- coding: utf-8 -*-
"""Language_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xnWodRn0B_RkY0ftni7BSRx0T7iwpcQu
"""

import time
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer, logging, pipeline

#initialization
MODEL_NAME = "bert-base-multilingual-uncased"
RANDOM_STATE = 9
BATCH_SIZE = 64
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_EPOCHS = 1
LEARNING_RATE = 5e-5

torch.backends.cudnn.deterministic = True
torch.manual_seed(RANDOM_STATE)
logging.set_verbosity_error()

#load the data
train_data = pd.read_csv("/content/sample_data/train.csv")
test_data = pd.read_csv("/content/sample_data/test.csv")
valid_data = pd.read_csv("/content/sample_data/valid.csv")

#concatenate the datasets into a single dataframe
lang_data = pd.concat([train_data, test_data, valid_data], ignore_index=True)

#displaying summary of the data
print("Combined Dataset Summary:")
print(lang_data.sample(n=30, random_state=RANDOM_STATE))

#plotting the structure of the target variable
lang_counts = lang_data["labels"].value_counts(normalize=True)
lang_counts.plot(kind="bar")
plt.title("Shares of objects in each language class", fontsize=15)
plt.ylabel("Proportion of objects")
plt.tight_layout()
plt.show()

#retrieving the text data
texts_data = lang_data["text"].values.astype("U")
#retrieving the labels data
labels_data = lang_data["labels"].values

#instantiating the LabelEncoder object
label_encoder = LabelEncoder()

#encoding the labels
labels_data_encoded = label_encoder.fit_transform(labels_data)
class_names = label_encoder.classes_

#displaying the encoding results
for idx, class_name in enumerate(class_names):
    print(f"{idx:<2} => {class_name}")

#splitting the data into training (80%) and the combination of validation and testing (20%)
training_texts, val_test_texts, train_labels, val_test_labels = train_test_split(
    texts_data, labels_data_encoded, train_size=0.8, random_state=RANDOM_STATE,stratify=labels_data_encoded,
)

#further splitting the validation and testing sets
validation_texts, testing_texts, validation_labels, testing_labels = train_test_split(
    val_test_texts, val_test_labels, test_size=0.5, random_state=RANDOM_STATE, stratify=val_test_labels
)

#verifying the correctness of dimensions
assert (
    training_texts.shape[0] + validation_texts.shape[0] + testing_texts.shape[0] == texts_data.shape[0]
)

#displaying the number of objects in each set
training_texts.shape[0], validation_texts.shape[0], testing_texts.shape[0]

#instantiating a BERT tokenizer
bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

#tokenizing the training examples
training_encodings = bert_tokenizer(
    list(training_texts),
    add_special_tokens=True,
    max_length=128,
    truncation=True,
    padding="max_length",
)

#tokenizing the validation examples
validation_encodings = bert_tokenizer(
    list(validation_texts),
    add_special_tokens=True,
    max_length=128,
    truncation=True,
    padding="max_length",
)

#tokenizing the testing examples
testing_encodings = bert_tokenizer(
    list(testing_texts),
    add_special_tokens=True,
    max_length=128,
    truncation=True,
    padding="max_length",
)

def display_encodings_info(
    tokenizer,
    encodings,
    texts,
    labels,
    text_idx
):

    #displaying the original text
    text = texts[text_idx]
    print(f"Input text:\n{text}\n")

    #displaying the language of the text
    lang_label = labels[text_idx]
    lang = class_names[lang_label]
    print(f"Language: {lang}\n")

    #displaying the encoded text
    text_encoded = encodings["input_ids"][text_idx]
    print(f"Tokenized input text (encoded):\n{text_encoded}\n")

    #displaying the decoded text
    text_decoded = tokenizer.convert_ids_to_tokens(text_encoded)
    print(f"Tokenized input text (decoded):\n{text_decoded}")

display_encodings_info(
    tokenizer=bert_tokenizer,
    encodings=training_encodings,
    texts=training_texts,
    labels=train_labels,
    text_idx=990,
)

display_encodings_info(
    tokenizer=bert_tokenizer,
    encodings=validation_encodings,
    texts=validation_texts,
    labels=validation_labels,
    text_idx=1033,
)

display_encodings_info(
    tokenizer=bert_tokenizer,
    encodings=testing_encodings,
    texts=testing_texts,
    labels=testing_labels,
    text_idx=1010,
)

#Creating Dataset and Dataloader
class LanguageDataset(Dataset):

    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __len__(self):
        dataset_length = len(self.labels)

        return dataset_length

    def __getitem__(self, idx):
        item = {key: torch.tensor(value[idx])
                for key, value in self.encodings.items()}
        item["labels"] = torch.tensor(self.labels[idx])

        return item

#initializing the training dataset
training_dataset = LanguageDataset(
    encodings=training_encodings,
    labels=train_labels,
)

#initializing the validation dataset
validation_dataset = LanguageDataset(
    encodings=validation_encodings,
    labels=validation_labels,
)

#initializing the testing dataset
testing_dataset = LanguageDataset(
    encodings=testing_encodings,
    labels=testing_labels,
)

#creating a training Dataloader
training_dataloader = DataLoader(
    training_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
)

#creating a validation Dataloader
validation_dataloader = DataLoader(
    validation_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
)

#creating a testing Dataloader
testing_dataloader = DataLoader(
    testing_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
)

print(f"Training data examples: {len(training_dataloader.dataset):,}")
print(f"Number of batches: {len(training_dataloader)}")
print(f"Batch size: {BATCH_SIZE}")

print(f"Validation data examples: {len(validation_dataloader.dataset)}")
print(f"Number of batches: {len(validation_dataloader)}")
print(f"Batch size: {BATCH_SIZE}")

print(f"Testing data examples: {len(testing_dataloader.dataset):,}")
print(f"Number of batches: {len(testing_dataloader)}")
print(f"Batch size: {BATCH_SIZE}")

#creating a mapping from predictions to label names
id2label_mappings = dict()
for i, name in enumerate(class_names):
    id2label_mappings[i] = name
id2label_mappings

#computing the number of classes
num_labels = len(class_names)

#instantiating the BERT model
bert_model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=num_labels,
    id2label=id2label_mappings,
)

#moving the model to DEVICE (GPU/CUDA)
bert_model.to(DEVICE)

#defining the optimization algorithm
optimizer = torch.optim.Adam(bert_model.parameters(), lr=LEARNING_RATE)

bert_model.eval()

def acc_score(model, dataloader, device=DEVICE):

    #preallocating counter variables
    correct_predictions, num_examples = 0, 0

    #turning off computing gradients
    with torch.no_grad():

        #iteratively computing accuracy score (batch by batch)
        for batch_idx, batch in enumerate(dataloader):

            #selecting the batch data (encodings, attention mask, labels)
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)

            #using BERT to compute logits
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs["logits"]

            #computing the predictions for labels
            predicted_labels = torch.argmax(logits, dim=1)

            #computing the number of examples/correct predictions number
            num_examples += labels.size(0)
            correct_predictions += (predicted_labels == labels).sum()

    #computing the final accuracy score
    accuracy_score = correct_predictions.float() / num_examples

    return accuracy_score

def train_bert_model(
    model,
    optimizer,
    training_dataloader,
    validation_dataloader,
    accuracy_score_func=acc_score,
    epochs=2,
    batch_log_freq=100,
    device=DEVICE
):

    #starting the timer
    start_time = time.time()

    #going through all epochs
    for epoch in range(epochs):

        #setting the model in the training mode
        model.train()

        #going through all batches
        for batch_idx, batch in enumerate(training_dataloader):

            #selecting the batch
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device).long()

            #BERT forward pass
            outputs = model(
                input_ids, attention_mask=attention_mask, labels=labels
            )
            loss, logits = outputs["loss"], outputs["logits"]

            #BERT backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            #logging the progress
            if not batch_idx % batch_log_freq:
                print (f"Epoch {epoch+1:03d}/{epochs:03d} | "
                       f"Batch {batch_idx:03d}/{len(training_dataloader):03d} | "
                       f"Loss = {loss:.4f}")

        #setting the model in the evaluation mode
        model.eval()

        #disabling computing gradients
        with torch.set_grad_enabled(False):
            # Computing training accuracy
            training_accuracy_score = accuracy_score_func(
                model=model,
                dataloader=training_dataloader,
            )
            #computing validation accuracy
            validation_accuracy_score = accuracy_score_func(
                model=model,
                dataloader=validation_dataloader,
            )
            #logging the accuracy scores
            print(f"\nTraining accuracy = "
                  f"{training_accuracy_score:.4f}"
                  f"\nValid accuracy = "
                  f"{validation_accuracy_score:.4f}\n")

        #printing the time passed at the end of the epoch
        time_elapsed_epoch = (time.time() - start_time) / 60
        print(f'Time elapsed: {time_elapsed_epoch:.2f} min\n')

    #printing the total time spent on BERT fine-tuning
    time_elapsed_total = (time.time() - start_time) / 60
    print(f'\nTotal training Time: {time_elapsed_total:.2f} min')

    return model

#training the BERT model
bert_model = train_bert_model(
    model=bert_model,
    optimizer=optimizer,
    training_dataloader=training_dataloader,
    validation_dataloader=validation_dataloader,
    epochs=NUM_EPOCHS,
    batch_log_freq=10,
)

def evaluate_test(model, dataloader, device=DEVICE):

    #setting up counter variables
    correct_preds, num_examples = 0, 0
    #preallocating the list for test predictions
    test_predictions = []

    #disabling computing gradients
    with torch.no_grad():

        #iterating through all batches
        for batch_idx, batch in enumerate(dataloader):

            #selecting the batch
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            labels = batch["labels"].to(device)

            #computing logits
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs["logits"]

            #computing the predictions for labels
            predicted_labels_batch = torch.argmax(logits, dim=1)

            #adding the batch predictions to the list
            test_predictions.append(predicted_labels_batch)

            #iteratively computing accuracy determinants
            num_examples += labels.size(0)
            correct_preds += (predicted_labels_batch == labels).sum().cpu()

    #computing final accuracy score
    test_accuracy_score = correct_preds.float() / num_examples

    #transforming a list of tensors into one tensor
    test_predictions_tensor = torch.cat(test_predictions).cpu()

    return test_accuracy_score, test_predictions_tensor

# Computing test accuracy and test predictions
accuracy_test, predictions_test = evaluate_test(
    model=bert_model, dataloader=testing_dataloader
)

print(f"Test accuracy: {accuracy_test:.4f}")

#defining the Transformers pipeline
bert_pipeline = pipeline(
    task="text-classification",
    model=bert_model,
    tokenizer=bert_tokenizer,
    device=DEVICE,
)

#predicting one text
def define_lang_one_text(pipeline, test_text):

    #applying the pipeline to make predictions
    one_text_results = pipeline(test_text)[0]
    #retrieving the probability
    proba = one_text_results["score"]
    #retrieving the predicted label (encoded)
    predicted_lang = one_text_results["label"]
    #displaying the prediction
    print(f"Predicted language: {predicted_lang} ({proba:.2%} probability)")

#creating a test text (English)
test_text = "It is interesting how we all turned out to be in the same place."
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

#creating a test text (Dutch)
test_text = "Ik kan het zien. Dankuwel!"
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

#creating a test text (Spanish)
test_text = "Si yo fuera Maradona viviría como él"
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

#creating a test text (German)
test_text = "Ich habe keine zeit. Auf Wiedersehen!"
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

#creating a test text (Russian)
test_text = "Что бы я делал без тебя, я не знаю"
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

# Creating a test text (Portuguese)
test_text = "Como chego à estação de trem? Como chego ao ponto de ônibus?"
print(f"Input text: {test_text}\n")

define_lang_one_text(pipeline=bert_pipeline, test_text=test_text)

#visualizing the predictions
print(classification_report(
    y_true=testing_labels,
    y_pred=predictions_test,
    target_names=class_names,
)
     )

ConfusionMatrixDisplay.from_predictions(
    testing_labels,
    predictions_test,
    display_labels=class_names,
    cmap="Blues",
)
plt.xticks(rotation=90)
plt.xlabel("Predicted language")
plt.ylabel("True language")
plt.title("Language recognition confusion matrix", fontsize=15)
plt.tight_layout()
plt.show()